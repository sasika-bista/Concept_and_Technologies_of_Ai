{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et9NXpkhAQih"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L-EcFBROIqq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYKKR52bHesB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOXxKAfVHjZf"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/finalPortfolioDatasets./Cleaned_dataset_for_classification_task.csv\",\n",
        "    encoding=\"latin1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjsUAKqGN9f8"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAH6RoLIRr15"
      },
      "outputs": [],
      "source": [
        "# Features\n",
        "X = df[['Year', 'Population(2022)', 'Area', '% of World', 'Density(km2)',\n",
        "                             'CO2_per_capita', 'Emission_Class']]\n",
        "\n",
        "# Target\n",
        "y = df['CO2 emission (Tons)']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fpER2SCMii6"
      },
      "outputs": [],
      "source": [
        "#======================================================================\n",
        "# PRIMARY MODEL 1: lINEAR REGRESSION\n",
        "# ======================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PRIMARY MODEL 1: lINEAR REGRESSION\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK0s13UCRvcq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKPvFXmBSi9k"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Initialize Ridge Regression model\n",
        "ridge = Ridge(alpha=1.0, random_state=42)  # alpha is the regularization strength\n",
        "\n",
        "# Train the model\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_ridge = ridge.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtNU2fnkNFDl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "# Metrics Function FOR BOTH RANDOM FOREST AND DTR\n",
        "def regression_metrics(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {\"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_lr = regression_metrics(y_test, y_pred_ridge)\n",
        "print(metrics_lr)"
      ],
      "metadata": {
        "id": "4x_MrVvFdYJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt65jobrYlN4"
      },
      "outputs": [],
      "source": [
        "# Using the trained Decision Tree (or Linear Regression)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sanity check dataframe\n",
        "sanity_check = pd.DataFrame({\n",
        "    'Country': df.loc[y_test.index, 'Country'],\n",
        "    'Year': X_test['Year'],\n",
        "    'Actual_CO2': y_test,\n",
        "    'Predicted_CO2': y_pred_ridge\n",
        "})\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred_ridge, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # perfect line\n",
        "plt.xlabel('Actual CO2 (Tons)')\n",
        "plt.ylabel('Predicted CO2 (Tons)')\n",
        "plt.title('Random forest: Predicted vs Actual CO2')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiSBKIH-NSuz"
      },
      "outputs": [],
      "source": [
        "#======================================================================\n",
        "# PRIMARY MODEL 2: DESICION TREE\n",
        "# ======================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PRIMARY MODEL 2: DESICION TREE\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDuhiHItTOYN"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dtr = DecisionTreeRegressor(random_state=42)\n",
        "dtr.fit(X_train, y_train)  # no scaling needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjZdSOnPNLaH"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Predictions\n",
        "y_pred_dtr = dtr.predict(X_test)\n",
        "\n",
        "metrics_dtr = regression_metrics(y_test, y_pred_dtr)\n",
        "\n",
        "metrics_dtr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-IylLXGYBvC"
      },
      "outputs": [],
      "source": [
        "# Using the trained Decision Tree (or Linear Regression)\n",
        "y_pred = dtr.predict(X_test)  # or lr.predict(X_test_scaled) for Linear Regression\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sanity check dataframe\n",
        "sanity_check = pd.DataFrame({\n",
        "    'Country': df.loc[y_test.index, 'Country'],\n",
        "    'Year': X_test['Year'],\n",
        "    'Actual_CO2': y_test,\n",
        "    'Predicted_CO2': y_pred\n",
        "})\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # perfect line\n",
        "plt.xlabel('Actual CO2 (Tons)')\n",
        "plt.ylabel('Predicted CO2 (Tons)')\n",
        "plt.title('Random: Predicted vs Actual CO2')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9u44ujmpuDo"
      },
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame({\n",
        "    \"Metric\": [\"MSE\", \"RMSE\", \"MAE\", \"R2\"],\n",
        "    \"Linear Regression\": list(metrics_lr.values()),\n",
        "    \"Decision Tree\": list(metrics_dtr.values())\n",
        "})\n",
        "\n",
        "comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grRvtqeCTBGy"
      },
      "source": [
        "R² ≈ 0.002 → Linear Regression explains almost none of the variance.\n",
        "\n",
        "RMSE/MAE very small → but scale might be small if your data is normalized or standardized.\n",
        "\n",
        "Clearly, Linear Regression is not capturing the relationships between features and CO2 emissions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tU_AXLxS_ZV"
      },
      "source": [
        "R² ≈ 0.91 → Decision Tree explains ~91% of variance → very strong.\n",
        "\n",
        "MSE / RMSE extremely low → predictions are very close to true values.\n",
        "\n",
        "Decision Tree is much better than Linear Regression on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ORT72NqceUk"
      },
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# FEATURE SELECTION\n",
        "# ======================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FEATURE SELECTION\")\n",
        "print('='*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO3NUGpwNq0v"
      },
      "outputs": [],
      "source": [
        "# ______________________________________________________________________\n",
        "#\n",
        "# LINEAR REGRESSION FEATURE SELECTION\n",
        "# ______________________________________________________________________\n",
        "\n",
        "print(\"_\"*70)\n",
        "print(\"\\nLINEAR REGRESSION FEATURE SELECTION\")\n",
        "print('_'*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF_IDpI7I0f3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Define features and target\n",
        "# Use only numeric independent features (safe)\n",
        "features = ['Year', 'Population(2022)', 'Area', '% of World', 'Density(km2)', \"Emission_Class\",\"CO2_per_capita\"]\n",
        "target = 'CO2 emission (Tons)'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Ridge Regression\n",
        "ridge = Ridge(alpha=1.0, random_state=42)\n",
        "\n",
        "# Initialize RFE with Ridge as estimator\n",
        "rfe_ridge = RFE(estimator=ridge, n_features_to_select=5)\n",
        "rfe_ridge.fit(X_train, y_train)\n",
        "\n",
        "# Create feature ranking table\n",
        "feature_ranking_ridge = pd.DataFrame({\n",
        "    \"Feature\": X_train.columns,\n",
        "    \"Ranking\": rfe_ridge.ranking_,\n",
        "    \"Selected\": rfe_ridge.support_\n",
        "}).sort_values(\"Ranking\")\n",
        "\n",
        "print(\"Ridge Regression Feature Ranking (via RFE):\\n\", feature_ranking_ridge)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e47tSiejOGX_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(9, 5))\n",
        "sns.barplot(\n",
        "    x=\"Ranking\",\n",
        "    y=\"Feature\",\n",
        "    data=feature_ranking_ridge\n",
        ")\n",
        "\n",
        "plt.title(\"Feature Ranking using Linear Regression\")\n",
        "plt.xlabel(\"Importance (Absolute Coefficient Value)\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l3AQqHOUtlS"
      },
      "source": [
        "Althtough, the ranking shows that co2_per_cap is a better feature than Area , because there is a high chance of data leakage from co2_per_capital, since CO2 emission = population * co2_per_cap so we will be ommiting the co2_per_captial and will be using the next best feature i.e. Density and since emission_class was also indirectly created using CO2 emission it shall also be replaced by the next closest features i.e population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R_I2fnoN68M"
      },
      "outputs": [],
      "source": [
        "# ______________________________________________________________________\n",
        "#\n",
        "# DECISION TREE FEATURE SELECTION\n",
        "# ______________________________________________________________________\n",
        "\n",
        "print(\"_\"*70)\n",
        "print(\"\\nDECISION TREE FEATURE SELECTION\")\n",
        "print('_'*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVap9PRYaP5u"
      },
      "outputs": [],
      "source": [
        "# Decision Tree RFE\n",
        "dtr = DecisionTreeRegressor(random_state=42)\n",
        "rfe_dt = RFE(estimator=dtr, n_features_to_select=5)  # select top 3 features\n",
        "rfe_dt.fit(X_train, y_train)\n",
        "\n",
        "selected_features_dt = X_train.columns[rfe_dt.support_]\n",
        "# feature ranking table\n",
        "feature_ranking_dt = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Ranking\": rfe_dt.ranking_,\n",
        "    \"Selected\": rfe_dt.support_\n",
        "}).sort_values(\"Ranking\")\n",
        "\n",
        "\n",
        "print(\"\\nDecision Tree Selected Features:\", list(selected_features_dt))\n",
        "print(\"\\nDecision Tree Feature Ranking:\\n\", feature_ranking_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FnXAXNtWh-0"
      },
      "outputs": [],
      "source": [
        "# viualizing the ranking\n",
        "\n",
        "plt.figure(figsize=(9, 5))\n",
        "sns.barplot(\n",
        "    x=\"Ranking\",\n",
        "    y=\"Feature\",\n",
        "    data=feature_ranking_dt\n",
        ")\n",
        "\n",
        "plt.title(\"Feature Ranking using RFE (Logistic Regression)\")\n",
        "plt.xlabel(\"Feature Rank (Lower = More Important)\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yJscVhdUAxg"
      },
      "source": [
        "Althtough, the ranking shows that co2_per_cap is a better feature than Area , because there is a high chance of data leakage from co2_per_capital, since CO2 emission = population * co2_per_cap so we will be ommiting the co2_per_captial and will be using the next best feature i.e. Area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNgVOHgNUkdu"
      },
      "outputs": [],
      "source": [
        "selected_features = ['Year', 'Population(2022)', '% of World', 'Density(km2)', 'Area']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuL9bkPGcq8l"
      },
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# HYPERPARAMETERE TUNNING\n",
        "# ======================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"HYPERPARAMETERE TUNNING\")\n",
        "print('='*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOKJ_Y8dOMhL"
      },
      "outputs": [],
      "source": [
        "# ______________________________________________________________________\n",
        "#\n",
        "# DECISION TREE HYPERPARAMETER TUNNING\n",
        "# ______________________________________________________________________\n",
        "\n",
        "print(\"_\"*70)\n",
        "print(\"\\nDECISION TREE HYPERPARAMETER TUNNING\")\n",
        "print('_'*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43_JRwBpdnFH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTfWA1_wGzFG"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Regressor\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "dt_params = {\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# GridSearchCV for Decision Tree\n",
        "dt_grid = GridSearchCV(\n",
        "    estimator=dt,\n",
        "    param_grid=dt_params,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "dt_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Decision Tree Best Hyperparameters:\", dt_grid.best_params_)\n",
        "print(\"Decision Tree Best CV Score (MSE):\", -dt_grid.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfh72nNyOXu_"
      },
      "outputs": [],
      "source": [
        "# ______________________________________________________________________\n",
        "#\n",
        "# LINEAR REGRESSION HYPERPARAMETER TUNNING\n",
        "# ______________________________________________________________________\n",
        "\n",
        "print(\"_\"*70)\n",
        "print(\"\\nLINEAR REGRESSION HYPERPARAMETER TUNNING\")\n",
        "print('_'*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQpUhOCALkGG"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Features\n",
        "X = df[['Year', 'Population(2022)', 'Area', '% of World', 'Density(km2)']]\n",
        "\n",
        "# Target\n",
        "y = df['CO2 emission (Tons)']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define Ridge model\n",
        "ridge = Ridge(random_state=42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0.01, 0.1, 1, 10, 100]  # regularization strengths to try\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "ridge_grid = GridSearchCV(\n",
        "    estimator=ridge,\n",
        "    param_grid=param_grid,\n",
        "    scoring='r2',\n",
        "    cv=5,                # 5-fold cross-validation\n",
        "    n_jobs=-1            # use all CPU cores\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "ridge_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameter\n",
        "print(\"Best alpha:\", ridge_grid.best_params_)\n",
        "\n",
        "# Best score (mean R² across CV folds)\n",
        "print(\"Best R² Score:\", ridge_grid.best_score_)\n",
        "\n",
        "# Make predictions on test set using best model\n",
        "best_ridge = ridge_grid.best_estimator_\n",
        "y_pred_ridge = best_ridge.predict(X_test)\n"
      ],
      "metadata": {
        "id": "uH09iafDgK7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1GY3PRgPCHe"
      },
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# PRIMARY MODELS AFTERS TUNNING AND FEATURE SELECTION\n",
        "# ======================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PRIMARY MODELS AFTERS TUNNING AND FEATURE SELECTION\")\n",
        "print('='*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONx0ot5WT1z6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "target = 'CO2 emission (Tons)'\n",
        "X = df\n",
        "y = df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y8u4V1SpVzu"
      },
      "outputs": [],
      "source": [
        "# Fit GridSearch using selected features\n",
        "ridge_grid.fit(X_train[selected_features], y_train)\n",
        "\n",
        "# Best Random Forest model is selected automatically\n",
        "ridge_best = ridge_grid.best_estimator_\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred_ridge = ridge_best.predict(X_test[selected_features])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAdU1I0CsS05"
      },
      "outputs": [],
      "source": [
        "print(ridge_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9Hs68S6pb0l"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "ridge_metrics = {\n",
        "    \"MSE\": mean_squared_error(y_test, y_pred_ridge),\n",
        "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_ridge)),\n",
        "    \"MAE\": mean_absolute_error(y_test, y_pred_ridge),\n",
        "    \"R2\": r2_score(y_test, y_pred_ridge)\n",
        "}\n",
        "\n",
        "ridge_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMpiGK4NpeED"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dt_final = DecisionTreeRegressor(\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=5,\n",
        "    min_samples_split=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dt_final.fit(X_train[selected_features], y_train)\n",
        "\n",
        "y_pred_dt = dt_final.predict(X_test[selected_features])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFaymcs6pgoW"
      },
      "outputs": [],
      "source": [
        "dt_metrics = {\n",
        "    \"MSE\": mean_squared_error(y_test, y_pred_dt),\n",
        "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_dt)),\n",
        "    \"MAE\": mean_absolute_error(y_test, y_pred_dt),\n",
        "    \"R2\": r2_score(y_test, y_pred_dt)\n",
        "}\n",
        "\n",
        "dt_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7pIrsLSpjgf"
      },
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame({\n",
        "    \"Metric\": [\"MSE\", \"RMSE\", \"MAE\", \"R2\"],\n",
        "    \"Linear Regression\": list(ridge_metrics.values()),\n",
        "    \"Decision Tree\": list(dt_metrics.values())\n",
        "})\n",
        "\n",
        "comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJRE-K7G9AgX"
      },
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# NEURAL NETWORK FOR REGRESSION TASK\n",
        "# ======================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"NEURAL NETWORK FOR REGRESSION TASK\")\n",
        "print('='*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHUUXUH19L26"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features and target\n",
        "features = ['Year', 'Population(2022)', '% of World', 'Density(km2)', 'Area']\n",
        "X = df[features]\n",
        "y = df['CO2 emission (Tons)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oJZEHg39Svu"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Neural Network pipeline\n",
        "nn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # always scale inputs for neural networks\n",
        "    ('nn', MLPRegressor(\n",
        "        hidden_layer_sizes=(100, 50),  # 2 hidden layers: 100 and 50 neurons\n",
        "        activation='relu',             # non-linear activation\n",
        "        solver='adam',                 # optimizer\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "nn_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_nn = nn_pipeline.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI_3LIOGttE1"
      },
      "outputs": [],
      "source": [
        "# nn on test set\n",
        "# Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred_nn)\n",
        "\n",
        "# Root Mean Squared Error\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred_nn)\n",
        "\n",
        "# R² score\n",
        "r2 = r2_score(y_test, y_pred_nn)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYc8JGrhtvbR"
      },
      "outputs": [],
      "source": [
        "# NN on training set\n",
        "y_train_pred = nn_pipeline.predict(X_train)\n",
        "\n",
        "# Mean Squared Error\n",
        "mse = mean_squared_error(y_train, y_train_pred)\n",
        "\n",
        "# Root Mean Squared Error\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = mean_absolute_error(y_train, y_train_pred)\n",
        "\n",
        "# R² score\n",
        "r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}