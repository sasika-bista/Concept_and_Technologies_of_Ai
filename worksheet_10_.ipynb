{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bERJLJczBEA",
        "outputId": "9d3e9831-c810-484c-fe14-6ed89a97b6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'imdb-movie-review-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/imdb-movie-review-dataset\n"
          ]
        }
      ],
      "source": [
        "#EXERCISE 1 : IMPLEMENTATION OF NAIVE BAYES ALGORITHM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import kagglehub\n",
        "  # Download latest version\n",
        "path = kagglehub.dataset_download(\"renanmav/imdb-movie-review-dataset\")\n",
        "print(\"Path to dataset files:\",path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "P0qmTcEg1Rf5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.listdir(path)\n",
        "movie_review_path = os.path.join(path,\"movie_data.csv\")\n",
        "df =pd.read_csv(movie_review_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "T17khGnG4haN"
      },
      "outputs": [],
      "source": [
        "reviews = df['review'].values\n",
        "#print(reviews.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYUdxeBt50xY",
        "outputId": "6ff52429-da78-4a7d-89ec-6911682f35f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This movie is just crap. Even though the directors claim to be part of that oi-culture, it\\'s still a very, very bad directorial debut. The topic itself is very interesting and I accept the bad acting due to the fact, that they are all amateurs and never acted before, but the worst thing about this film are the dialogs and very unexperienced and naive directing. There\\'s no timing at all in that movie. I felt like the directors were so exited to do that movie (it\\'s their first feature), that they actually never really asked themselves, what story they wanna tell. I met Ben (one of the directors) on several occasions and he\\'s a nice and thoughtful guy, but that doesn\\'t make him a director. I think, that \"American History X\" is full of clichÃ©s, but somehow manages to transport a story. \"Oi!Warning\" is full of clichÃ©s, doesn\\'t tell anything new or provocative and (-that\\'s the sad thing about this movie) it\\'s far from any Oi!-Reality.<br /><br />If you wanna see weird but great German films, watch the movies of Michael Haneke, Christoph Schlingensief, Oskar Roehler, Hans Weingartner or Oliver Hirschbiegel:<br /><br />Benny\\'s Video Funny Games Die UnberÃ¼hrbare Mein Letzter Film Das Experiment Das Weisse Rauschen MuxmÃ¤uschenstill ...<br /><br />*** out of ten, because of the topic and the photography'\n",
            " 'Another detailed work on the subject by Dr Dwivedi takes us back in time to pre-partioned Panjab. Dr Dwivedi chose a difficult subject for his movie debut. He has worked on all meticulous details to bring the story to life. The treatment of the subject is very delicate.<br /><br />Even though we have not been to the region during that time, the sets and costumes look real. Unlike most movies made on partition, this one focuses not on the gory details of violence to attract audience, but on its after-effects. The characters come to life. Priyanshu Chatterjee has given an impressive performance. Manoj Bajpai has acted his heart out showing the plight of a guilt-ridden man. The rest of the cast has done a good job too.'\n",
            " 'THE CAT O\\'NINE TAILS (Il Gatto a Nove Code) <br /><br />Aspect ratio: 2.35:1 (Cromoscope)<br /><br />Sound format: Mono<br /><br />(35mm and 70mm release prints)<br /><br />A blind ex-journalist (Karl Malden) overhears a blackmail plot outside a genetics research laboratory and later teams up with a fellow reporter (James Franciscus) to investigate a series of murders at the lab, unwittingly placing their own loved ones at the mercy of a psychopathic killer.<br /><br />Rushed into production following the unexpected worldwide success of his directorial debut THE BIRD WITH THE CRYSTAL PLUMAGE (1969), Dario Argento conceived THE CAT O\\'NINE TAILS as a giallo-thriller in much the same vein as its forerunner, toplining celebrated Hollywood actor Karl Malden - fresh from his appearance in PATTON (1969) - and rising star Franciscus (THE VALLEY OF GWANGI). Sadly, the resulting film - which the ads claimed was \\'nine times more suspenseful\\' than \"Bird\" - is a disappointing follow-up, impeccably photographed and stylishly executed, but too plodding and aimless for general consumption.<br /><br />Malden and Franciscus are eminently watchable in sympathetic roles, and cinematographer Enrico Menczer (THE DEAD ARE ALIVE) uses the wide Cromoscope frame to convey the hi-tech world in which Argento\\'s dark-hearted scenario unfolds, but the subplot involving Euro starlet Catherine Spaak (THE LIBERTINE) as Franciscus\\' romantic interest amounts to little more than unnecessary padding. Highlights include an unforgettable encounter with the black-gloved assassin in a crowded railway station (edited with sleek assurance by cult movie stalwart Franco Fraticelli), and a nocturnal episode in which Malden and Franciscus seek an important clue inside a mouldering tomb and fall prey to the killer\\'s devious machinations. But despite these flashes of brilliance, the film rambles aimlessly from one scene to the next, simmering gently without ever really coming to the boil. It\\'s no surprise that \"Cat\" failed to emulate the runaway success of \"Bird\" when released in 1971.<br /><br />(English version)'\n",
            " ...\n",
            " 'By the time this film was released I had seen Chorus Line on stage 4 times, and had been anticipating most eagerly the long-rumored production of a film of the story. My wife and I were in line hours before the box office opened on the day the film was released. It was not just a disappointment, it was a kick in the abdomen. <br /><br />First, the story was \"moved outside,\" so to speak, by including scenes not in the confines of the theater. Those confines are a large portion of the meaning and impact of the story. <br /><br />Second & Third together (assign your own order): one of the original songs, with very dynamic dance number, was removed; a song which was NOT in the stage production was added. Say what ?? I\\'m confused! <br /><br />The only reason I gave this film 2 stars instead of 1 is my admiration for the talent and hard work of the performers. I\\'ve now seen Chorus Line on stage 6 times, and wouldn\\'t mind seeing it 6 more times before I die. It is superbly written, with wonderful music, and heart- wrenchingly true stories. If you want to see a musical which includes a great \"cattle call\" audition, I recommend All That Jazz. If you want to see the story of A Chorus Line, see it on stage.'\n",
            " 'Well, if you like pop/punk, punk, ska, and a tad bit of modern psycho billy, then seeing the live performances are about the only thing worth watching. This movie has tons and tons of band cameos, along with president of Troma, Lloyd Kaufman as a semi-major role, and lots of goofy death scenes. Sounds like it may be good, right? Well, the deaths keep coming, and repeatedly to many different bands of the Warp Tour and the fans at the event. Some of the deaths start of stylish, but then they are recycled over and over, to the point of being completely repetitive. Almost everyone dies of having their head smashed, or intestines being pulled from their stomach. The gore looks as if it was from Andreas Schnaas\\' \"Zombie 90: Extreme Pestilence\"; with this being the \"watered-down type blood\", but now that movie is actually decent, and provides humor-something that this movie terribly lacks. Sure, the movie is made by Doug Sakmann from Troma, it\\'s got great low-budget potential, and it tries...but just too hard. Everything is overly meant to be funny in this movie, and thats what brings it down. Everything tries to be too comic and goofy, by using intentional bad acting, an overuse of pointless deaths, and doing the same thing...over and over. It\\'s basically \"Mulva: Zombie Ass-Kicker\", \"Chairman of the Board\", or any movie you have made with your friends: it\\'s funny to those who made it, and that\\'s about it.<br /><br />Great potential, great idea, great use of effects-but it\\'s the same thing...over and over: A band plays, a band dies, fans die. Everyone dies, blood is sprayed everywhere, the process is repeated.<br /><br />The question is for these types of movies-which is basically \\'bad slap-stick\\'-do they try too hard, or not at all?'\n",
            " 'Where this movie is faithful to Burroughs\\' vision, it is excellent; where it departs from Burroughs, it is superb. It is a tale of family, of the seeking of a father by a real and emotional orphan. Lambert\\'s speaking of one of the most anguished lines in all of cinema \"He was my Father!\" is enough to bring tears to the eyes of the most cynical critic. Not a perfect motion picture - the notorious over-dubbing of McDowell\\'s voice by Glenn Close is unconscionable and only explicable in terms of a very British error - but a fine if flawed masterpiece and a noble farewell to Sir Ralph Richardson.']\n"
          ]
        }
      ],
      "source": [
        "print(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c6PcWv66ncF",
        "outputId": "4693de56-147c-49ef-c88c-d95b769ed045"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49969"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "reviews.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rXQXAGyY78g_"
      },
      "outputs": [],
      "source": [
        "reviews_lower = [text.lower() for text in reviews]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcsU4dGm3TwQ",
        "outputId": "0ccab8b0-ccdd-4c63-d0ad-7def203e37da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxAzTFLV2rsE",
        "outputId": "ec11b4be-08a5-4866-817b-25ae7fe5f1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: Hello! This is a SAMPLE email with numbers 123 and special #tags.\n",
            "Cleaned: hello sample email number special tag\n"
          ]
        }
      ],
      "source": [
        "#remove non-alpha calues\n",
        "import re\n",
        "def clean_text(text, remove_stopwords=True, use_stemming=False):\n",
        "  text = text.lower()\n",
        "  text=re.sub(r'[^a-zA-Z\\s]','',text)\n",
        "  words = text.split()\n",
        "  if remove_stopwords:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "\n",
        "  if use_stemming:\n",
        "    stemmer = PorterStemmer()\n",
        "    words =[stemmer.stem(w) for w in words]\n",
        "  else:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(w) for w in words]\n",
        "\n",
        "  return ' '.join(words)\n",
        "sample_text = \"Hello! This is a SAMPLE email with numbers 123 and special #tags.\"\n",
        "print(\"Original:\", sample_text)\n",
        "print(\"Cleaned:\", clean_text(sample_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "U7X9osXA4crY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d752117c-2a81-4f09-e702-014b6bfcd509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['amazing' 'annoying' 'are' 'emails' 'hate' 'is' 'learning' 'love'\n",
            " 'machine' 'spam']\n",
            "\n",
            "Document-Term Matrix shape: (4, 10)\n",
            "\n",
            "Matrix (dense representation):\n",
            "[[0 0 0 0 0 0 1 1 1 0]\n",
            " [1 0 0 0 0 1 1 0 1 0]\n",
            " [0 0 0 1 1 0 0 0 0 1]\n",
            " [0 1 1 1 0 0 0 0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "#CountVectorizer Example\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"I love machine learning\",\n",
        "    \"Machine learning is amazing\",\n",
        "    \"I hate spam emails\",\n",
        "    \"Spam emails are annoying\"\n",
        "]\n",
        "\n",
        "# Create CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform\n",
        "X_counts = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Vocabulary:\", count_vectorizer.get_feature_names_out())\n",
        "print(\"\\nDocument-Term Matrix shape:\", X_counts.shape)\n",
        "print(\"\\nMatrix (dense representation):\")\n",
        "print(X_counts.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xvx1_3da56HV",
        "outputId": "e0b3096b-554c-455b-eeb6-ee2f4ff52ab1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     1\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     1\n",
              "8     0\n",
              "9     1\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    1\n",
              "15    0\n",
              "16    0\n",
              "17    1\n",
              "18    0\n",
              "19    1\n",
              "20    1\n",
              "21    0\n",
              "22    0\n",
              "23    1\n",
              "24    1\n",
              "25    1\n",
              "26    0\n",
              "27    1\n",
              "28    1\n",
              "29    1\n",
              "30    1\n",
              "31    0\n",
              "32    1\n",
              "33    0\n",
              "34    1\n",
              "35    1\n",
              "36    1\n",
              "37    0\n",
              "38    0\n",
              "39    0\n",
              "40    1\n",
              "41    0\n",
              "42    0\n",
              "43    0\n",
              "44    0\n",
              "45    0\n",
              "46    0\n",
              "47    1\n",
              "48    1\n",
              "49    0\n",
              "Name: sentiment, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.a\n",
        "df['cleaned_review'] = df[\"review\"].apply(lambda x: clean_text(x, remove_stopwords=True, use_stemming=True))\n",
        "\n",
        "print(\"Original review example:\")\n",
        "print(df.loc[0, 'review'])\n",
        "print(\"\\nCleaned review example:\")\n",
        "print(df.loc[0, 'cleaned_review'])\n",
        "print(f\"\\nBinary labels: {df['sentiment'].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i26EYft41vAq",
        "outputId": "bd2c852e-1df8-4edb-febd-a58b909918f9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original review example:\n",
            "This movie is just crap. Even though the directors claim to be part of that oi-culture, it's still a very, very bad directorial debut. The topic itself is very interesting and I accept the bad acting due to the fact, that they are all amateurs and never acted before, but the worst thing about this film are the dialogs and very unexperienced and naive directing. There's no timing at all in that movie. I felt like the directors were so exited to do that movie (it's their first feature), that they actually never really asked themselves, what story they wanna tell. I met Ben (one of the directors) on several occasions and he's a nice and thoughtful guy, but that doesn't make him a director. I think, that \"American History X\" is full of clichÃ©s, but somehow manages to transport a story. \"Oi!Warning\" is full of clichÃ©s, doesn't tell anything new or provocative and (-that's the sad thing about this movie) it's far from any Oi!-Reality.<br /><br />If you wanna see weird but great German films, watch the movies of Michael Haneke, Christoph Schlingensief, Oskar Roehler, Hans Weingartner or Oliver Hirschbiegel:<br /><br />Benny's Video Funny Games Die UnberÃ¼hrbare Mein Letzter Film Das Experiment Das Weisse Rauschen MuxmÃ¤uschenstill ...<br /><br />*** out of ten, because of the topic and the photography\n",
            "\n",
            "Cleaned review example:\n",
            "movi crap even though director claim part oicultur still bad directori debut topic interest accept bad act due fact amateur never act worst thing film dialog unexperienc naiv direct there time movi felt like director exit movi first featur actual never realli ask stori wanna tell met ben one director sever occas he nice thought guy doesnt make director think american histori x full clich somehow manag transport stori oiwarn full clich doesnt tell anyth new provoc that sad thing movi far oirealitybr br wanna see weird great german film watch movi michael hanek christoph schlingensief oskar roehler han weingartn oliv hirschbiegelbr br benni video funni game die unberhrbar mein letzter film da experi da weiss rauschen muxmuschenstil br br ten topic photographi\n",
            "\n",
            "Binary labels: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import re"
      ],
      "metadata": {
        "id": "xA84xNT63q01"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['cleaned_review'],\n",
        "    df['sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentiment']\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "print(f\"\\nTraining class distribution:\\n{y_train.value_counts(normalize=True)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arB6icEU2bAs",
        "outputId": "61f7e54b-9545-457d-f367-5714dd846259"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 39975 samples\n",
            "Testing set: 9994 samples\n",
            "\n",
            "Training class distribution:\n",
            "sentiment\n",
            "0    0.500038\n",
            "1    0.499962\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=3000)\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "9Vqn3JSA3FCj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the model\n",
        "nb_classifier = MultinomialNB(alpha=1.0)  # alpha=1 for Laplace smoothing\n",
        "nb_classifier.fit(X_train_vec, y_train)\n",
        "print(\"Model trained successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLAwPiat3JIp",
        "outputId": "a3f1bab8-172f-41ad-c197-ee9493f39993"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nb_classifier.predict(X_test_vec)\n",
        "y_pred_proba = nb_classifier.predict_proba(X_test_vec)"
      ],
      "metadata": {
        "id": "XbUjO4O53SFM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkYsqzdP7eZD",
        "outputId": "639e1799-e31d-49fe-f302-9d623e27a395"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8358014808885331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH86Xr0A7fYY",
        "outputId": "3c40fa08-d179-42d0-a5fc-ed5d92b80fb7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84      4998\n",
            "           1       0.84      0.83      0.84      4996\n",
            "\n",
            "    accuracy                           0.84      9994\n",
            "   macro avg       0.84      0.84      0.84      9994\n",
            "weighted avg       0.84      0.84      0.84      9994\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzx9Tv9j7iK-",
        "outputId": "2ae176a1-f92e-4916-a7b2-b7412e695f70"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[4195  803]\n",
            " [ 838 4158]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "LjxeflIE7pnS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uuy2s9Sd8JGo",
        "outputId": "8a782595-8f0b-4390-9efd-320b6ba70877"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.99997337e-01 2.66293101e-06]\n",
            " [9.25547929e-01 7.44520710e-02]\n",
            " [9.99795700e-01 2.04300444e-04]\n",
            " ...\n",
            " [2.54081943e-04 9.99745918e-01]\n",
            " [3.00843784e-03 9.96991562e-01]\n",
            " [1.01045259e-01 8.98954741e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qiWJOVFO8IY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7abgTXZv7jsl",
        "outputId": "975ef3d4-b697-47d0-c435-b03fed46127c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9053769826585558\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}